services:
  postgres:
    image: postgres
    container_name: postgres-spark-metastore
    environment:
      - POSTGRES_DB=metastore_db
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hive
    ports:
      - 5432:5432
    networks:
      - spark-net
    volumes:
      - pg-data:/mnt/pg-data

  spark-master:
    image: spark
    container_name: spark-master
    hostname: "spark-master"
    stdin_open: true
    tty: true
    command: "/spark/sbin/start-master.sh"
    environment:
      - SPARK_NO_DAEMONIZE=TRUE
    ports:
      - "7077:7077"
      - "8080:8080"
      - "4040:4040"
    #healthcheck:
    depends_on:
      - postgres
    networks:
      - spark-net
    volumes:
      - spark-vol:/mnt/data
    
  spark-client:
    image: spark-client
    container_name: spark-client
    hostname: "spark-client"
    stdin_open: true
    tty: true
    #command: "spark/bin/pyspark"
    command: bash
    environment:
      - SPARK_NO_DAEMONIZE=TRUE
    ports:
      - "8889:8889"
    networks:
      - spark-net
    volumes_from:
      - spark-master

  spark-worker-1:
    image: spark
    container_name: spark-worker-1
    hostname: spark-worker-1
    stdin_open: true
    tty: true
    command: "/spark/sbin/start-worker.sh spark://spark-master:7077"
    environment:
      - SPARK_NO_DAEMONIZE=TRUE
    ports:
      - "8081:8081"
    depends_on:
      - spark-master
    networks:
      - spark-net
    volumes_from:
      - spark-master

  spark-worker-2:
    image: spark
    container_name: spark-worker-2
    hostname: spark-worker-2
    stdin_open: true
    tty: true
    command: "/spark/sbin/start-worker.sh spark://spark-master:7077"
    environment:
      - SPARK_NO_DAEMONIZE=TRUE
    ports:
      - "8082:8081"
    depends_on:
      - spark-master
    #environment:
      #- VAR=foo
    networks:
      - spark-net
    volumes_from:
      - spark-master

networks:
  spark-net:
    name: spark-net

volumes:
  spark-vol:
    name: spark-vol
  pg-data:
    name: pg-data
