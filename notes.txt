pyspark --conf "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension"

http://172.174.39.75:8889/lab?token=e89b8e9d242d26cee9b9563f11cce3f57d2c2ddcfb2cdc7f


docker buildx create --name mybuilder
docker buildx use mybuilder


docker buildx build \
  --push \
  --platform linux/arm64/v8,linux/amd64 \
  --tag saundr00/spark:v1 \
  --file Dockerfile.spark .

docker buildx build \
  --push \
  --platform linux/arm64/v8,linux/amd64 \
  --tag saundr00/spark-client:v1 \
  --file Dockerfile.spark-client .

sudo docker compose -f spark.yml up -d
sudo docker compose -f spark.yml down


sudo docker build -f Dockerfile.metastore -t spark-metastore .
docker run --rm -d -p 5432:5432 --env SERVICE_NAME=metastore \
  --env POSTGRES_USER=postgres --env POSTGRES_PASSWORD=postgres \
  --name spark-metastore-standalone \
  spark-metastore
docker exec -it spark-metastore-standalone bash
cd /var/lib/postgres/apache-hive-3.1.2-bin/bin
./schematool -dbType postgres -driver org.postgresql.Driver \
-url jdbc:postgresql://localhost:5432/metastore_db \
-userName postgres -passWord postgres -initSchema
pg_dump -U postgres --create metastore_db > $HOME/metastore_db.sql
exit
docker cp spark-metastore-standalone:/root/metastore_db.sql ./db_init/init_01.sql
